"""
Comprehensive tests for record-level validation rules.

This test suite covers all record validation checks including duplicate detection,
blank record detection, and unique key validation.

Author: Daniel Edge
"""

import pytest
import pandas as pd

from validation_framework.validations.builtin.record_checks import (
    DuplicateRowCheck,
    BlankRecordCheck,
    UniqueKeyCheck
)
from tests.conftest import create_data_iterator


# ============================================================================
# DUPLICATE ROW CHECK TESTS
# ============================================================================

@pytest.mark.unit
class TestDuplicateRowCheck:
    """Test DuplicateRowCheck validation."""
    
    def test_no_duplicates(self):
        """Test validation passes when there are no duplicate rows."""
        df = pd.DataFrame({
            "id": [1, 2, 3, 4, 5],
            "name": ["Alice", "Bob", "Charlie", "Diana", "Eve"],
            "value": [100, 200, 300, 400, 500]
        })
        
        validation = DuplicateRowCheck()
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is True
        assert result.failed_count == 0
    
    def test_exact_duplicate_rows_detected(self):
        """Test validation fails when there are exact duplicate rows."""
        df = pd.DataFrame({
            "id": [1, 2, 2, 3, 3],
            "name": ["Alice", "Bob", "Bob", "Charlie", "Charlie"],
            "value": [100, 200, 200, 300, 300]
        })
        
        validation = DuplicateRowCheck()
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is False
        assert result.failed_count > 0
    
    def test_duplicate_on_subset_columns(self):
        """Test duplicate detection on specific columns."""
        df = pd.DataFrame({
            "id": [1, 2, 2, 3],
            "name": ["Alice", "Bob", "Bob", "Charlie"],
            "timestamp": ["2025-01-01", "2025-01-02", "2025-01-03", "2025-01-04"]
        })
        
        validation = DuplicateRowCheck(subset=["id", "name"])
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is False
    
    def test_no_duplicates_on_subset(self):
        """Test validation passes when subset has no duplicates."""
        df = pd.DataFrame({
            "id": [1, 2, 3, 4],
            "name": ["Alice", "Bob", "Charlie", "Diana"],
            "value": [100, 100, 100, 100]  # Duplicates in value column
        })
        
        validation = DuplicateRowCheck(subset=["id"])
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is True


# ============================================================================
# BLANK RECORD CHECK TESTS
# ============================================================================

@pytest.mark.unit
class TestBlankRecordCheck:
    """Test BlankRecordCheck validation."""
    
    def test_no_blank_records(self):
        """Test validation passes when there are no blank records."""
        df = pd.DataFrame({
            "id": [1, 2, 3],
            "name": ["Alice", "Bob", "Charlie"],
            "email": ["a@test.com", "b@test.com", "c@test.com"]
        })
        
        validation = BlankRecordCheck()
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is True
    
    def test_completely_blank_rows_detected(self):
        """Test validation fails when there are completely blank rows."""
        df = pd.DataFrame({
            "id": [1, None, 3],
            "name": ["Alice", None, "Charlie"],
            "email": ["a@test.com", None, "c@test.com"]
        })
        
        validation = BlankRecordCheck()
        result = validation.validate(create_data_iterator(df), {})
        
        # Row 2 is completely blank
        assert result.passed is False
    
    def test_partially_blank_rows_not_flagged(self):
        """Test that partially blank rows are not flagged as blank records."""
        df = pd.DataFrame({
            "id": [1, 2, 3],
            "name": ["Alice", None, "Charlie"],  # Row 2 has some data
            "email": ["a@test.com", "b@test.com", "c@test.com"]
        })
        
        validation = BlankRecordCheck()
        result = validation.validate(create_data_iterator(df), {})
        
        # Row 2 is not completely blank
        assert result.passed is True
    
    def test_empty_strings_as_blank(self):
        """Test that rows with only empty strings are considered blank."""
        df = pd.DataFrame({
            "id": [1, "", 3],
            "name": ["Alice", "", "Charlie"],
            "email": ["a@test.com", "", "c@test.com"]
        })
        
        validation = BlankRecordCheck()
        result = validation.validate(create_data_iterator(df), {})
        
        # Row 2 has only empty strings
        assert result.passed is False


# ============================================================================
# UNIQUE KEY CHECK TESTS
# ============================================================================

@pytest.mark.unit
class TestUniqueKeyCheck:
    """Test UniqueKeyCheck validation."""
    
    def test_all_keys_unique(self):
        """Test validation passes when all key values are unique."""
        df = pd.DataFrame({
            "id": [1, 2, 3, 4, 5],
            "name": ["Alice", "Bob", "Charlie", "Diana", "Eve"]
        })
        
        validation = UniqueKeyCheck(key_fields=["id"])
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is True
    
    def test_duplicate_keys_detected(self):
        """Test validation fails when there are duplicate keys."""
        df = pd.DataFrame({
            "id": [1, 2, 2, 3, 3],
            "name": ["Alice", "Bob", "Bob2", "Charlie", "Charlie2"]
        })
        
        validation = UniqueKeyCheck(key_fields=["id"])
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is False
        assert result.failed_count > 0
    
    def test_composite_key_all_unique(self):
        """Test validation with composite (multi-column) keys."""
        df = pd.DataFrame({
            "first_name": ["John", "John", "Jane", "Jane"],
            "last_name": ["Smith", "Doe", "Smith", "Doe"],
            "dob": ["1990-01-01", "1985-05-15", "1992-03-20", "1988-11-10"]
        })
        
        validation = UniqueKeyCheck(key_fields=["first_name", "last_name"])
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is True
    
    def test_composite_key_duplicates_detected(self):
        """Test detection of duplicates in composite keys."""
        df = pd.DataFrame({
            "first_name": ["John", "John", "Jane"],
            "last_name": ["Smith", "Smith", "Doe"],
            "email": ["john1@test.com", "john2@test.com", "jane@test.com"]
        })
        
        validation = UniqueKeyCheck(key_fields=["first_name", "last_name"])
        result = validation.validate(create_data_iterator(df), {})
        
        assert result.passed is False
    
    def test_null_keys_handled(self):
        """Test handling of null values in key fields."""
        df = pd.DataFrame({
            "id": [1, None, 3, None],
            "name": ["Alice", "Bob", "Charlie", "Diana"]
        })
        
        validation = UniqueKeyCheck(key_fields=["id"])
        result = validation.validate(create_data_iterator(df), {})
        
        # Null keys should be detected as duplicates or handled appropriately
        assert result.passed is False or result.passed is True  # Depends on implementation


# ============================================================================
# INTEGRATION TESTS
# ============================================================================

@pytest.mark.integration
class TestRecordValidationsIntegration:
    """Integration tests for record-level validations."""
    
    def test_combined_record_validations(self):
        """Test multiple record validations together."""
        df = pd.DataFrame({
            "id": [1, 2, 3, 4, 5],
            "name": ["Alice", "Bob", "Charlie", "Diana", "Eve"],
            "email": ["a@test.com", "b@test.com", "c@test.com", "d@test.com", "e@test.com"]
        })
        
        # Run all record validations
        dup_check = DuplicateRowCheck()
        blank_check = BlankRecordCheck()
        unique_check = UniqueKeyCheck(key_fields=["id"])
        
        dup_result = dup_check.validate(create_data_iterator(df), {})
        blank_result = blank_check.validate(create_data_iterator(df), {})
        unique_result = unique_check.validate(create_data_iterator(df), {})
        
        # All should pass for clean data
        assert dup_result.passed is True
        assert blank_result.passed is True
        assert unique_result.passed is True
    
    def test_dirty_data_detected(self):
        """Test record validations detect various data quality issues."""
        df = pd.DataFrame({
            "id": [1, 2, 2, None, 5],
            "name": ["Alice", "Bob", "Bob", None, "Eve"],
            "email": ["a@test.com", "b@test.com", "b@test.com", None, "e@test.com"]
        })
        
        # Run validations
        dup_check = DuplicateRowCheck()
        blank_check = BlankRecordCheck()
        unique_check = UniqueKeyCheck(key_fields=["id"])
        
        dup_result = dup_check.validate(create_data_iterator(df), {})
        blank_result = blank_check.validate(create_data_iterator(df), {})
        unique_result = unique_check.validate(create_data_iterator(df), {})
        
        # Should detect issues
        assert dup_result.passed is False  # Row 2 and 3 are duplicates
        assert blank_result.passed is False  # Row 4 is blank
        assert unique_result.passed is False  # Duplicate IDs


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
